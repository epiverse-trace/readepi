---
title: "Package Design vignette for {readepi}"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Package Design vignette for {readepi}}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{css, echo = FALSE}
.section {
  opacity: 1;
}
```

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment  = "#>"
)
```

## Concept and motivation

::: {style="text-align: justify;"}

This document outlines the design decisions guiding the development strategies 
of the `{readepi}` R package, the reasoning behind them, as well as the 
possible pros and cons of each decision.

Importing data from various sources into the R environment is the first step 
in the workflow of outbreak analysis. Health data are often stored in 
individual files of different formats, in relational database management 
systems (RDBMS), and more importantly, many health organizations store their 
data in health information systems (HIS) wrapped underhood of a specific 
Application Programming Interfaces (APIs).

Many R packages have been developed over the years to read data stored in a 
file or in a directory containing multiple files. We recommend the 
[{rio}](http://gesistsa.github.io/rio/) package for importing data 
that are relatively small in size and the 
[{data.table}](https://cran.r-project.org/web/packages/data.table/vignettes/) 
package for large files. For retrieving data from RDBMS, we recommend the 
[{DBI}](https://dbi.r-dbi.org/) package.

There are several R packages for reading data from HIS such as {fingertipsR}, 
{REDCapR}, {godataR}, and {globaldothealth}, which are used to fetch data from 
[Fingertips](https://fingertips.phe.org.uk/), 
[REDCap](https://projectredcap.org/software/), 
[Go.Data](https://www.who.int/tools/godata), and 
[Global.Health](https://global.health/) respectively. However, these packages 
are usually designed to read from specific HIS and can't be used to query 
others. This increases the dependency on many other packages and introduces 
the challenge of having a unified framework for importing data from multiple 
HIS. As such, we propose `{readepi}`, a centralized tool that will provide 
users with the capability of importing data from various HIS and RDBMS.

`{readepi}` can import data from several potential sources in the same way. The
 data sources include distributed health information systems and public 
 databases as shown in the figure below.
:::

![readepi roadmap](../man/figures/roadmap_readepi.drawio.svg)

## Scope

::: {style="text-align: justify;"}

The `{readepi}` package is designed to import data from two common sources of 
institutional health-related data: HIS wrapped with specific APIs and 
RDBMS that run on specific servers.

To import data from these sources, users must have the appropriate access and
provide relevant query parameters to fetch the target data. Thus, the 
`{readepi}` package is structured around one main function, `read_epidata()`,
 and two auxiliary functions, `authenticate()` and `get_metadata()`.

The current version of `{readepi}` supports importing data from HIS APIs such 
as REDCap, DHIS2, and Fingertips, as well as RDBMS like MS SQL, SQLite, MySQL, 
and PostgreSQL.

In the future, we plan to include features for reading data from additional 
HISs like GoData, Globaldothealth, SORMAS, and ODK, as well as RDBMS such as 
MS Access.

:::

![readepi design diagram](../man/figures/readepi_design_diagram.drawio.svg)


## Output

::: {style="text-align: justify;"}
The `read_epidata()` functions return a `list` object containing one or more `data frames`. Each `data frame` corresponds to the data from a specified source.
The `get_metadata()` function returns a data dictionary containing information about the data structure.
The `authenticate()` function returns a connection object that is used in the query request.
:::

## Design decisions

::: {style="text-align: justify;"}
The aim of {readepi} is to simplify and standardize the process of fetching 
health data from APIs and servers. We strive to make it easy for users, 
requiring minimal arguments to access and retrieve the data of interest from 
the target source.

* `authenticate()`:  This function verifies the user's identity and determines 
if they are authorized to access the requested database or API. Establishing 
this connection is crucial for ensuring successful data import.

Once authentication credentials are provided, they are securely stored within 
the connection object. This prevents the need to re-supply them for subsequent 
requests to other functions. The Figure below lists the arguments needed to 
call the `authenticate()` function.
:::

```{r authenticate, fig.align='center', echo=FALSE}
DiagrammeR::grViz("digraph{
 
      graph[rankdir = LR]
  
      node[shape = rectangle, style = filled, fontname = Courier,
      align = center]
  
      subgraph cluster_0 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = LightBlue
    
        label = 'authenticate()'
        node[shape = rectangle, fillcolor = LemonChiffon, margin = 0.25]
        A[label = 'type: the source name']
        B[label = 'from: the URL, or IP address, or hostname']
        C[label = 'user_name: the user name']
        D[label = 'password: the password or API token or key']
        E[label = 'db_name: the database name (RDBMS only)']
        F[label = 'port: the port id (RDBMS only)']
        G[label = 'driver_name: the driver name (RDBMS only)']
      }
      
}")

```

::: {style="text-align: justify;"}
The `type` argument refers to the name of the data source of interest. The 
current version of the package  covers the following types:

    i) RDBMS: “MS SQL”, “MySQL”, “PostgreSQL”, “SQLite”
    ii) APIs: “REDCap”, “DHIS2”,  “Fingertips”.

Here's a refined version of your description:

---

**`get_metadata()`**: This function retrieves the data schema, including the 
list of tables and data dictionary, from a database or the data dictionary 
from an API endpoint. It ensures compatibility with the 
`clean_based_on_dictionary()` function of the 
[{cleanepi}](https://epiverse-trace.github.io/cleanepi/) R package for 
 data cleaning and standardization processes.
:::

```{r get_metadata, fig.align='center', echo=FALSE}
DiagrammeR::grViz("digraph{
 
      graph[rankdir = LR]
  
      node[shape = rectangle, style = filled, fontname = Courier,
      align = center]
  
      subgraph cluster_0 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = LightBlue
    
        label = 'get_metadata()'
        node[shape = rectangle, fillcolor = LemonChiffon, margin = 0.25]
        A[label = 'conn: the connection object made from authenticate()']
        B[label = 'endpoint: the path to the target endpoint (APIs only)']
        C[label = 'query: a list with the query parameters']
      }
}")
```

* `read_epidata()`: this is the main function of the package. 
It can be used to read from both HIS and RDBMS as shown in the below figure.

```{r read, fig.align='center', echo=FALSE}
DiagrammeR::grViz("digraph{
 
      graph[rankdir = LR]
  
      node[shape = rectangle, style = filled, fontname = Courier,
      align = center]
  
      subgraph cluster_0 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = LightBlue
    
        label = 'read_epidata()'
        node[shape = rectangle, fillcolor = LemonChiffon, margin = 0.25]
        A[label = 'conn: the connection object made from authenticate()']
        B[label = 'endpoint: the path to the target endpoint (APIs only)']
        C[label = 'query: a list with the query parameters']
      }
}")
```

::: {style="text-align: justify;"}

Calling `read_epidata()` will invoke an internal function (`read_*`, 
where `*` represents the source name) that is dedicated 
to fetching data from specific HIS sources. This design allows for targeted 
updates to individual functions while maintaining the overall structure, 
ensuring ease of maintenance.
:::

```{r fig.align='center', echo=FALSE}
DiagrammeR::DiagrammeR("
graph TB
    A[read_epidata]
    A --> B(read_rdbms)
    A --> D(read_redcap)
    A --> E(read_dhis2)
    A --> F(read_fingertips)
    A --> G(read_sormas)
    A --> H(read_ODK)
    A --> I(read_godata)
")
```

::: {style="text-align: justify;"}
Note that, when reading from RDBMS, the `query` argument could be an [SQL query]{.underline} or a [list with a vector of table names, fields and rows to subset on]{.underline}.
For HIS, the elements of this list can vary depending on the API that is been queried. We strongly recommend reading the vignette on the [query_parameters](./query_parameters.Rmd) for more details.
:::

## Mitigate API security risks


To mitigate API security risks, we implement the following best practices:

1. Utilize an API gateway as a centralized entry point and direct all 
authentication requests through this gateway.
2. Ensure users only access authorized data:
   - Prefer OAuth or token-based authentication, whenever possible
   - Implement access controls to enforce data restrictions and provide 
   meaningful error messages for unauthorized access attempts.
3. Avoid including API keys in URLs to prevent exposure in proxy logs or 
other places.
4. Implement rate limiting to control the number of requests per time period 
and the size of API responses.
5. Mitigate risks of malicious data:
   - Use parameterized queries to prevent SQL injection.
   - Validate and sanitize input data to prevent cross-site scripting (XSS) 
   and other attacks.
6. Maintain robust security measures:
   - Regularly review and decommission unused APIs.
   - Maintain an updated list of all endpoints to ensure security and 
   operational integrity.


## Dependencies

* The `read_epidata()` will rely mainly on 2 packages:

  [{httr2}](https://CRAN.R-project.org/package=httr2) or [{data.table}](https://CRAN.R-project.org/package=data.table): this will serve in constructing and performing the API requests,
  [{dplyr}](https://CRAN.R-project.org/package=dplyr): will be used for its data wrangling functionalities.

* The `read_from_server()` will rely mainly on the packages below:

  [{DBI}](https://CRAN.R-project.org/package=DBI): for its functionalities to connect, and fetch data from a table in a database,
  [{pool}](https://CRAN.R-project.org/package=pool): for its ability to handle multiple connection,
  [{odbc}](https://CRAN.R-project.org/package=odbc): for its drivers required to fetch data from several DBMS,
  [{RMySQL}](https://CRAN.R-project.org/package=RMySQL): for its drivers to fetch data from MySQL databases.

It also has a system dependency for OS-X and Linux users. This will be described in details in the vignette.

Both functions will require all other packages that are needed in the package development process including:

  [{checkmate}](https://CRAN.R-project.org/package=checkmate),
  [{httptest2}](https://CRAN.R-project.org/package=httptest2),
  [{bookdown}](https://CRAN.R-project.org/package=bookdown),
  [{rmarkdown}](https://CRAN.R-project.org/package=rmarkdown),
  [{testthat}](https://CRAN.R-project.org/package=testthat) (>= 3.0.0),
  [{knitr}](https://CRAN.R-project.org/package=knitr)

## Contribute

There are no special requirements to contributing to {readepi}, please follow the [package contributing guide](https://github.com/epiverse-trace/.github/blob/main/CONTRIBUTING.md).
